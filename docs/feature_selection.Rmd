---
title: "feature_selection"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#devtools::load_all()
library(tidyverse)
library(magrittr)
library(rstan)
library(foreach)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

my_theme = 	
	theme_bw() +
	theme(
		panel.border = element_blank(),
		axis.line = element_line(),
		panel.grid.major = element_line(size = 0.2),
		panel.grid.minor = element_line(size = 0.1),
		text = element_text(size=12),
		legend.position="bottom",
		aspect.ratio=1,
		axis.text.x = element_text(angle = 90, hjust = 1),
		strip.background = element_blank(),
		axis.title.x  = element_text(margin = margin(t = 10, r = 10, b = 10, l = 10)),
		axis.title.y  = element_text(margin = margin(t = 10, r = 10, b = 10, l = 10))
	)

nb_to_gamma = function(mu, phi){
	list(
		"shape" = (mu*phi)/(mu+phi), 
		"rate" = phi/(mu+phi)
	)
}

source("https://gist.githubusercontent.com/stemangiola/dd3573be22492fc03856cd2c53a755a9/raw/e4ec6a2348efc2f62b88f10b12e70f4c6273a10a/tidy_extensions.R")

```

## R Markdown
```{r, cache=TRUE}
# TEMPORARY
load("/stornext/Home/data/allstaff/m/mangiola.s/PhD/deconvolution/ARMET/docs/fit_MPI_level1.RData")
load("/stornext/Home/data/allstaff/m/mangiola.s/PhD/deconvolution/ARMET/docs/level_1_input.RData")

xxx = fit_MPI %>%
summary() %$% summary %>%
as_tibble(rownames="par") %>%
filter(grepl("lambda|sigma", par)) %>%
separate(par, c("par", "G"), sep="\\[|\\]") %>%
filter(par %in% c("lambda", "sigma_raw")) %>%
select(par, G, "50%") %>% spread(par, "50%") %>%
mutate(G = G %>% as.integer) %>%
left_join(
	data_for_stan_MPI$symbols %>%
		gather(idx_MPI, symbol) %>%
		drop_na() %>% mutate(G=1:n())
) %>%
left_join( counts_stan_MPI %>% distinct(symbol, `level 1`)  ) %>%

# QQ plots

left_join(counts) %>%
do_parallel_start(40, "symbol") %>%
do({

	`%>%` = magrittr::`%>%`
	library(tidyverse)
	library(magrittr)

	(.) %>%
		group_by(symbol) %>%
		do(
			(.) %>%
				arrange(`read count normalised`) %>%
				mutate(
					predicted_NB =
						qnbinom(
							ppoints(`read count normalised`),
							size=.$sigma_raw %>% unique %>% exp %>% `^` (-1),
							mu=.$lambda %>% unique %>% exp
						)
				)
		) %>%
		ungroup()
}) %>%
do_parallel_end() %>%
mutate(`log of error` = (`read count normalised` - predicted_NB) %>% abs %>% `+` (1) %>% log) %>%
mutate(`error of log` = (log(`read count normalised` + 1) - log(predicted_NB + 1)) ) %>%
mutate(`error scaled` =  ((`read count normalised` - predicted_NB) / (`read count normalised` + 1) )) %>%
left_join(
	(.) %>%
		group_by(symbol) %>%
		summarise(`gene error mean` = `error of log` %>% abs %>% mean)
)

xxx %>%

mutate(
	symbol =
		gsub(
			(.) %>%
				distinct(`level 1`) %>%
				pull(1) %>%
				paste("_", sep="") %>%
				paste(collapse="|") ,
			"",
			symbol
		)
) 
```


```{r, cache=TRUE}

l1 = read_csv("~/unix3XX/PhD/deconvolution/ARMET/docs/fit_level1.csv") 

l1.annot = 
	l1 %>%
	
	# Recalculate error mean
	select(-`gene error mean`) %>%
	left_join(
	(.) %>%
		group_by(symbol) %>%
		summarise(`gene error mean` = `error of log` %>% abs %>% mean)
	) %>%
	
	# Convert to gamma
	mutate(
		shape = nb_to_gamma(lambda %>% exp, 1/exp(sigma_raw)) %$% shape,
		rate = nb_to_gamma(lambda %>% exp, 1/exp(sigma_raw)) %$% rate
	) %>%

	# Calculate confidence interval	
	mutate(CI_low = qgamma(0.025, shape = shape, rate = rate)) %>%
	mutate(CI_high = qgamma(0.975, shape = shape, rate = rate)) %>%
	
	distinct(symbol, `level 1`, lambda, CI_low, CI_high, shape, rate, `gene error mean`) %>%
	
	arrange(CI_low %>% desc) %>%
	
	left_join( (.) %>% count(symbol)  ) %>%
	filter(n == (.) %>% distinct(`level 1`) %>% nrow %>% `-` (1))

```

## Plot error rank

The threshold seems to be 0.5

```{r}
(
	l1.annot %>% 
 	unite(symbol_ct, c("symbol", "level 1"), remove=F) %>% 
 	sample_frac(0.01)  %>% 
 	arrange(`gene error mean` %>% desc) %>%
  mutate(symbol_ct = factor(symbol_ct, unique(symbol_ct))) %>%
  ggplot(aes(x = symbol_ct, y = `gene error mean` , color=`level 1`, size=lambda)) +
 	#geom_point(alpha=0.4)  + 
	geom_jitter(alpha=0.4, width = 25) +
 	theme(
 		axis.title.x=element_blank(),
	 axis.text.x=element_blank(),
	 axis.ticks.x=element_blank()
	) 
) %>% plotly::ggplotly()
```

```{r}
foreach(ct = l1.annot %>% distinct(`level 1`) %>% pull(1), .combine = bind_rows) %do% {
	l1.annot %>%
		mutate(is_ct = `level 1` == !!ct) %>%
		group_by(is_ct, symbol) %>%
		summarise(CI_low_sum = CI_low %>% sum, CI_high_sum = CI_high %>% sum	) %>%
		ungroup() %>%
		mutate(CI = ifelse(is_ct == T, CI_low_sum, CI_high_sum)) %>%
		select(symbol, is_ct, CI) %>%
		spread(is_ct, CI) %>%
		mutate(delta = `TRUE` - `FALSE`) %>%
		left_join( l1.annot %>% filter(`level 1` == ct) %>% distinct(symbol, lambda) ) %>%
		filter(lambda > 4) %>%
		arrange(delta %>% desc) %>%
		mutate(ct = ct) %>% 
		head(n=10)
} %>%
{
	(.) %>%
		distinct(`symbol original`) %>%
		write_csv("docs/markers.csv")
	(.)
} %>%
	left_join(
		l1 %>% distinct(`level 1`, symbol, sample, `read count normalised`)
	) %>%
	ggplot(aes(y=`read count normalised`, x=`level 1`)) + geom_boxplot() + facet_wrap(~ ct + symbol )

	
```

```{r, cache=TRUE}





l1 %>% 
  filter(symbol %in% c("GK3P")) %>%
	ggplot(aes(x=`predicted_NB` + 1, y=`read count normalised` + 1, label=symbol, color=`Cell type formatted`)) + 
	geom_abline(intercept = 0, slope = 1, color="grey") + 
	geom_point() + 
	facet_wrap(~ symbol, scales = "free")  +
	expand_limits(y=1, x=1) + 
	scale_y_log10() +
	scale_x_log10() +
	my_theme 


fit_MPI %>%
summary() %$% summary %>%
as_tibble(rownames="par") %>%
filter(grepl("lambda|sigma", par)) %>%
separate(par, c("par", "G"), sep="\\[|\\]") %>%
filter(par %in% c("lambda", "sigma_raw")) %>%
select(par, G, "50%") %>% spread(par, "50%") %>%
mutate(G = G %>% as.integer) %>%
left_join(
	data_for_stan_MPI$symbols %>%
		gather(idx_MPI, symbol) %>%
		drop_na() %>% mutate(G=1:n())
) %>%
left_join( counts_stan_MPI %>% distinct(symbol, `level 1`)  ) %>% 
	ggplot(aes(lambda, color=`level 1`)) + geom_density()

```

